{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import transformers\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import html\n",
    "import regex\n",
    "from IPython.display import clear_output\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This commercial really just reminded me what scumbags Verizon are [1, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "dataDict = pickle.load(open('redditSamples.pkl', 'rb'))\n",
    "#fear, sadness, joy, anger\n",
    "x = dataDict['samples'] \n",
    "y = dataDict['labels']\n",
    "print(x[0], y[0])\n",
    "def Inference(samples, model, disp=True):\n",
    "    model.eval()\n",
    "    tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-cased')\n",
    "    all_probs=[]\n",
    "    for batch_index, sample in enumerate(samples):\n",
    "\n",
    "        inputs = tokenizer.encode_plus(sample, None,add_special_tokens=True,max_length = 512,pad_to_max_length=True)\n",
    "\n",
    "        ids = torch.unsqueeze((torch.tensor(inputs[\"input_ids\"], dtype=torch.long)).to(device, dtype=torch.long), 0)\n",
    "        token_type_ids = (torch.tensor(inputs[\"token_type_ids\"], dtype=torch.long)).to(device, dtype=torch.long)\n",
    "        mask = torch.unsqueeze((torch.tensor(inputs['attention_mask'], dtype=torch.long)).to(device, dtype=torch.long), 0)\n",
    "\n",
    "        # Zero out any previously calculated gradients\n",
    "        model.zero_grad()\n",
    "        #Forward Pass (faux inference)\n",
    "        logits = model(ids, mask)\n",
    "        clear_output(wait=True)\n",
    "        #nn.Softmax(dim=1)\n",
    "        probabilities = (logits).detach().cpu().numpy()[0]\n",
    "        all_probs.append(probabilities)\n",
    "        \n",
    "        \n",
    "    #fear, sadness, joy, anger\n",
    "\n",
    "    if disp:\n",
    "        for index, sample in enumerate(samples):\n",
    "            print(f'Text: \\\"{sample}\\\"')\n",
    "            #print(f'Logits: {logits[0].detach().cpu().numpy()}\\n')\n",
    "            ##order is Negative, Neutral, Positive\n",
    "            percentages = all_probs[index]#may not work, delete code around if model actually softmaxes outputs\n",
    "            #percentages = [100*num for num in all_probs[index]]\n",
    "            #anger,disgust,fear,joy,sadness\n",
    "            print(f'{100*percentages[0]:.2f}% anger, {100*percentages[1]:.2f}% disgust, {100*percentages[2]:.2f}% fear, {100*percentages[3]:.2f}% joy, {100*percentages[4]:.2f}% sadness')\n",
    "    return all_probs\n",
    "HASHTAG_CHARS = r\"\\p{L}\\p{M}\\p{Nd}_\\u200c\\u200d\\ua67e\\u05be\\u05f3\\u05f4\\uff5e\\u301c\\u309b\\u309c\\u30a0\\u30fb\\u3003\\u0f0b\\u0f0c\\u00b7\"\n",
    "\n",
    "def process_tweet(tweet):\n",
    "    \"\"\"Remove all URLs (e.g. www.xyz.com), hash tags (e.g. #topic), targets (@username)\"\"\"\n",
    "    \n",
    "    tweet = regex.sub(r\"https?://t\\.co/[a-zA-Z0-9]+\",\n",
    "                                \"\", tweet)\n",
    "\n",
    "    tweet = regex.sub(r\"(?:([^\\w!#$%&*@＠]|^)|(?:^|[^\\w+~.-])(?:rt|rT|Rt|RT):?)[@＠](\\w{1,20}(?:/[a-zA-Z][\\w-]{0,24})?)\",\n",
    "                                r\"\\1\\2\", tweet)\n",
    "\n",
    "    tweet  = regex.sub(r\"(^|\\ufe0e|\\ufe0f|[^&\" +\n",
    "                                HASHTAG_CHARS +\n",
    "                                r\"])[#＃]((?!\\ufe0f|\\u20e3)[\" +\n",
    "                                HASHTAG_CHARS +\n",
    "                                r\"]*[\\p{L}\\p{M}][\" +\n",
    "                                HASHTAG_CHARS +\n",
    "                                r\"]*)\",\n",
    "                                r\"\\1\\2\", tweet)\n",
    "\n",
    "    tweet = regex.sub(r\"\\n+\",\n",
    "                                \"\\n\", tweet)\n",
    "\n",
    "    tweet = regex.sub(r\"\\s+\",\n",
    "                                \" \", tweet).strip()\n",
    "\n",
    "    tweet = html.unescape(tweet)\n",
    "\n",
    "    return tweet\n",
    "\n",
    "import matplotlib.pyplot\n",
    "def graphLoss(losses):\n",
    "    rang = np.linspace(1, len(losses), num=len(losses), dtype=int)\n",
    "    plt.plot(rang, losses)\n",
    "\n",
    "\n",
    "\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('batch')\n",
    "    plt.show()\n",
    "    \n",
    "def getDataloaders(shuff=False, fileName='redditSamples.pkl', batch_size=4, val_fraction=1):\n",
    "    dataDict = pickle.load(open(fileName, 'rb'))\n",
    "    x = dataDict['samples'] \n",
    "    y = dataDict['labels']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=23)\n",
    "\n",
    "\n",
    "    train_dataset = DATALoader(\n",
    "    data=X_train,\n",
    "    target=y_train,\n",
    "    max_length=512\n",
    "    )\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,\n",
    "    shuffle=shuff\n",
    "    )\n",
    "\n",
    "    #print(train_dataset[0])\n",
    "    index = int(len(X_test)*val_fraction)\n",
    "    val_dataset = DATALoader(\n",
    "    data=X_test[:index],\n",
    "    target=y_test[:index],\n",
    "    max_length=512\n",
    "    )\n",
    "\n",
    "    val_data_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,\n",
    "    shuffle=shuff\n",
    "    )\n",
    "    \n",
    "    \n",
    "    debug_set = DATALoader(\n",
    "    data=X_test[:10],\n",
    "    target=y_test[:10],\n",
    "    max_length=512\n",
    "    )\n",
    "\n",
    "    debug_loader = torch.utils.data.DataLoader(\n",
    "    debug_set, \n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    "    shuffle=shuff\n",
    "    )\n",
    "    \n",
    "    return train_data_loader, val_data_loader, debug_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DATALoader:\n",
    "    def __init__(self, data, target, max_length):\n",
    "        self.data = data\n",
    "        self.target = target #make sure to convert the target into numerical values\n",
    "        self.tokeniser = transformers.BertTokenizer.from_pretrained('bert-base-cased')\n",
    "        self.truncation=True\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        data = str(self.data[item])\n",
    "        data = \" \".join(data.split())\n",
    "        inputs = self.tokeniser.encode_plus(\n",
    "            data, \n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length = self.max_length,\n",
    "            pad_to_max_length=True\n",
    "            \n",
    "        )\n",
    "        \n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        padding_length = self.max_length - len(ids)\n",
    "        ids = ids + ([0] * padding_length)\n",
    "        mask = mask + ([0] * padding_length)\n",
    "        token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "\n",
    "        \n",
    "        #added code to allow for inference function (needs to accept inpout without targets)\n",
    "        if self.target == []:\n",
    "            targets = []\n",
    "        else:\n",
    "            targets = torch.tensor(self.target[item], dtype=torch.float)\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': targets\n",
    "        }\n",
    "\n",
    "from transformers import BertModel\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.layer1 = nn.Sequential(nn.Dropout(dropout), nn.Linear(768, 100), nn.ReLU(),nn.BatchNorm1d(100),nn.Linear(100, 5), nn.ReLU() )\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        \n",
    "        out = self.layer1(pooled_output)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(data_loader, model=None, optimizer=None, device=None, scheduler=None, epochs=None, loss_fn =None, val=True):\n",
    "    print(\"Beginning training...\\n\")\n",
    "    ep_losses = []\n",
    "    best_loss=1\n",
    "    for epoch_i in range(epochs):\n",
    "        print(f\"Epoch: {epoch_i+1}\\n\")\n",
    "\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "        losses = []\n",
    "        for batch_index, sample in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "\n",
    "            \n",
    "            #Load batch variabes to GPU\n",
    "            ids = (sample[\"ids\"]).to(device, dtype=torch.long)\n",
    "            token_type_ids = (sample[\"token_type_ids\"]).to(device, dtype=torch.long)\n",
    "            mask = (sample[\"mask\"]).to(device, dtype=torch.long)\n",
    "            targets = (sample[\"targets\"]).to(device, dtype=torch.float) \n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "            #Forward Pass (faux inference)\n",
    "            logits = model(ids, mask)\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "\n",
    "            print(f\"\\n\\n Logits:{logits}, \\nTargets: {targets} \\n\\n\")\n",
    "            loss = loss_fn(logits, targets)\n",
    "\n",
    "            print(f\"LOSS: {loss}\")\n",
    "        \n",
    "            #Backpropagate the loss\n",
    "            loss.backward()\n",
    "        \n",
    "            #Using the internally stored gradients, update weights/biases according to optimizer\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            #Save most performant model\n",
    "\n",
    "            \n",
    "\n",
    "             # Calculate the average loss over the entire training data\n",
    "            #avg_train_loss = total_loss / len(data_loader)\n",
    "            #print(f'Average Loss: {avg_train_loss}')\n",
    "            \n",
    "            losses.append(loss)\n",
    "        if val:\n",
    "            losses = validate(model, valDataLoader)\n",
    "            avg_loss = np.mean(losses)\n",
    "            ep_losses.append(avg_loss)\n",
    "            if avg_loss > best_loss:\n",
    "                        pickle.dump({'epoch': epoch_i,\n",
    "                                    'model_state_dict': model.state_dict()}, open(MODELPATH, 'wb'))\n",
    "                        print(\"\\nModel Saved!\")\n",
    "                        best_loss = loss\n",
    "    print(f\"Average Validation Loss: {avg_loss}\")\n",
    "    return losses, ep_losses\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODELPATH = os.getcwd() +\"\\\\model\\\\model.bin\"\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataLoader, valDataLoader, debugLoader = getDataloaders(False,fileName='redditSamples.pkl', batch_size=BATCH_SIZE, val_fraction = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Logits:tensor([[0.0000, 0.9176, 0.4498, 0.3190, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1219, 0.7910, 0.0000],\n",
      "        [0.2189, 1.0043, 0.5207, 0.3633, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.1827, 0.1011],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.3237],\n",
      "        [0.7334, 0.3633, 0.0000, 0.0588, 1.0572],\n",
      "        [0.3469, 0.5016, 0.4491, 0.0000, 0.0000],\n",
      "        [0.4177, 0.0000, 0.0252, 0.0000, 0.0382]], grad_fn=<ReluBackward0>), \n",
      "Targets: tensor([[0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0.],\n",
      "        [0., 1., 1., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0.]]) \n",
      "\n",
      "\n",
      "LOSS: 0.24474266171455383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2285 [00:22<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9056/4170191065.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mep_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainDataLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9056/872463915.py\u001b[0m in \u001b[0;36mTrain\u001b[1;34m(data_loader, model, optimizer, device, scheduler, epochs, loss_fn, val)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;31m#Backpropagate the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;31m#Using the internally stored gradients, update weights/biases according to optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Applications\\Anaconda\\envs\\Twitter\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Applications\\Anaconda\\envs\\Twitter\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "\n",
    "useSavedModel = False\n",
    "model = BertClassifier()\n",
    "if useSavedModel:\n",
    "        print(\"Loading Saved Model...\")\n",
    "        checkpoint = pickle.load(open(MODELPATH, 'rb'))\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(\"\\nModel Loaded!\")\n",
    "\n",
    "        \n",
    "l_r =1e-4\n",
    "# l_r = 5e-5\n",
    "#eps = 1e-8\n",
    "eps = 1e-8\n",
    "epochs=1\n",
    "BATCH_SIZE=8\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "devName = 'cpu'\n",
    "\n",
    "\n",
    "total_steps = len(trainDataLoader) * epochs\n",
    "optimizer = AdamW(model.parameters(), lr=l_r, eps=eps)\n",
    "device = torch.device(devName)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps) #0 is default for warmup steps\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "losses, ep_losses = Train(trainDataLoader, model, optimizer, device, scheduler, epochs, loss_fn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: \"i hate dogs!\"\n",
      "0.00% anger, 23.97% disgust, 0.60% fear, 0.00% joy, 0.00% sadness\n",
      "Text: \"I love pretty cats!\"\n",
      "0.00% anger, 24.62% disgust, 0.00% fear, 0.00% joy, 0.00% sadness\n",
      "Text: \"There will be heavy rainstorms tomorrow\"\n",
      "0.00% anger, 23.34% disgust, 0.05% fear, 0.00% joy, 0.29% sadness\n",
      "Text: \"fuck i am angry\"\n",
      "0.00% anger, 23.83% disgust, 1.65% fear, 0.00% joy, 0.01% sadness\n"
     ]
    }
   ],
   "source": [
    "samples = [\"i hate dogs!\", \"I love pretty cats!\",  \"There will be heavy rainstorms tomorrow\", 'fuck i am angry']\n",
    "probs = Inference(samples, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graphLoss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), MODELPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=768, out_features=100, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=100, out_features=3, bias=True)\n",
       "    (4): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_dict = torch.load(os.getcwd()+'/torchCHECKPT/model.pkl', map_location='cuda:0')\n",
    "model = BertClassifier()\n",
    "model.load_state_dict(stat_dict)\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data_loader):\n",
    "\n",
    "    #model.load_state_dict(torch.load(MODELPATH))\n",
    "    device = 'cuda'\n",
    "    model.eval()\n",
    "    \n",
    "    losses = []\n",
    "    for batch_index, sample in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        #Load batch variabes to GPU\n",
    "        ids = (sample[\"ids\"]).to(device, dtype=torch.long)\n",
    "        token_type_ids = (sample[\"token_type_ids\"]).to(device, dtype=torch.long)\n",
    "        mask = (sample[\"mask\"]).to(device, dtype=torch.long)\n",
    "        targets = (sample[\"targets\"]).to(device, dtype=torch.float) \n",
    "\n",
    "        # Zero out any previously calculated gradients\n",
    "        model.zero_grad()\n",
    "        #Forward Pass (faux inference)\n",
    "        logits = model(ids, mask)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        loss = loss_fn(logits, targets)\n",
    "\n",
    "        print(f\"LOSS: {loss}\")\n",
    "\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "    return losses\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cce259c0d54fe5bffe13af26804447aa3dbdd9a7daf1d33523d66f0df070ca6e"
  },
  "kernelspec": {
   "display_name": "PyTorch-1.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
