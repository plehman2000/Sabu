{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "getSentiment_optimization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPwvKem6hviOrywWFdZcNaP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plehman2000/TwitterProject/blob/Optimization/DataModelling/getSentiment/getSentiment_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizing Deep Learning Model for Sentiment Analysis"
      ],
      "metadata": {
        "id": "CInluZBWMsq0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyzing current model."
      ],
      "metadata": {
        "id": "erz1oek_fqch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing dependencies."
      ],
      "metadata": {
        "id": "rNoSHhHdMt7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install torchviz"
      ],
      "metadata": {
        "id": "g4f2K7sPMum1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "from termcolor import colored, cprint\n",
        "from transformers import BertModel\n",
        "from graphviz import Source\n",
        "import transformers\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchviz"
      ],
      "metadata": {
        "id": "PvrI-uQvMurp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Debugger."
      ],
      "metadata": {
        "id": "4VwXP0YxWGAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.debugger import Tracer"
      ],
      "metadata": {
        "id": "7_sH45BBWGQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data."
      ],
      "metadata": {
        "id": "DhIlBY_nNr9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples = np.asarray(a=list([\n",
        "    \"This movie is so painful to watch.\",\n",
        "    \"I cannot even fathom how gruesome the accident was.\",\n",
        "    \"Springtime is such a refreshing season to go out and play.\",\n",
        "    \"I love the sweet flavors of icecream.\"\n",
        "]))"
      ],
      "metadata": {
        "id": "94mjk_7BPW8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rrZ8aL2uPdlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model."
      ],
      "metadata": {
        "id": "0-oUpXNyMuwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.5):\n",
        "        super(BertClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        self.layer1 = nn.Sequential(\n",
        "          nn.Dropout(dropout),\n",
        "          nn.Linear(768, 100),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(100, 3),\n",
        "          nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, input_id, mask):\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        out = self.layer1(pooled_output)\n",
        "        return out"
      ],
      "metadata": {
        "id": "CkJxbs3KMvlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GITHUB_REPO_BRANCH = 'https://www.github.com/plehman2000/TwitterProject/tree/main'\n",
        "# MODELPATH = GITHUB_REPO_BRANCH +'/DataModelling/getSentiment/sentimentModel/'\n",
        "# stat_dict = torch.load(MODELPATH + 'model.pkl', map_location='cuda')\n",
        "model = BertClassifier()\n",
        "# model.load_state_dict(stat_dict)\n",
        "model.to('cuda')\n",
        "device = torch.device('cuda')"
      ],
      "metadata": {
        "id": "MlrUQ4fZQtfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for `getSentiment` function."
      ],
      "metadata": {
        "id": "StLx8qmTNdAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tracer = Tracer(colors='Linux')\n",
        "disp = True\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-cased')\n",
        "  all_probs=[]\n",
        "  for batch_index, sample in enumerate(samples):\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        text=sample,\n",
        "        text_pair=None,\n",
        "        add_special_tokens=True,\n",
        "        max_length=512,\n",
        "        pad_to_max_length=True\n",
        "    )\n",
        "\n",
        "    # debugging\n",
        "    print(f'inputs dictionary with length: {len(inputs)}')\n",
        "    print(inputs)\n",
        "\n",
        "    ids = torch.unsqueeze((torch.tensor(inputs[\"input_ids\"], dtype=torch.long)).to(device, dtype=torch.long), 0)\n",
        "    token_type_ids = (torch.tensor(inputs[\"token_type_ids\"], dtype=torch.long)).to(device, dtype=torch.long)\n",
        "    mask = torch.unsqueeze((torch.tensor(inputs['attention_mask'], dtype=torch.long)).to(device, dtype=torch.long), 0)\n",
        "\n",
        "    # debugging\n",
        "    cprint(text=f'ids with shape {ids.shape}:\\n{ids}\\n', color='blue')\n",
        "    cprint(text=f'token_type_ids with shape {token_type_ids.shape}:\\n{token_type_ids}\\n', color='yellow')\n",
        "    cprint(text=f'mask with shape {mask.shape}:\\n{mask}\\n', color='green')\n",
        "\n",
        "    # Zero out any previously calculated gradients\n",
        "    model.zero_grad()\n",
        "\n",
        "    #Forward Pass (faux inference)\n",
        "    logits = model(input_id=ids, mask=mask)\n",
        "\n",
        "    # saving graphviz of model per sample\n",
        "    torchviz.make_dot(var=logits, params=dict(model.named_parameters())).render(filename=str(batch_index), format='png')\n",
        "\n",
        "    # debugging\n",
        "    print(f'logits:\\n{logits}')\n",
        "\n",
        "    probabilities = (logits).detach().cpu().numpy()[0]\n",
        "    all_probs.append(probabilities)\n",
        "\n",
        "  if disp:\n",
        "    for index, sample in enumerate(samples):\n",
        "      print(f'Text: \\\"{sample}\\\"')\n",
        "      ##order is Negative, Neutral, Positive\n",
        "      percentages = all_probs[index]\n",
        "      \n",
        "      print(f'{100*percentages[0]:.2f}% Negative, {100*percentages[1]:.2f}% Neutral, {100*percentages[2]:.2f}% Positive')\n"
      ],
      "metadata": {
        "id": "GQ9LeVwcNdMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ipywidgets import SelectionSlider\n",
        "graph_selected = SelectionSlider(options=np.arange(start=1, stop=samples.size + 1))\n",
        "graph_selected"
      ],
      "metadata": {
        "id": "jhI6pyhLNdUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Source.from_file(filename=str(graph_selected.value))"
      ],
      "metadata": {
        "id": "lCNBbVH6NdXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensorRT Optimization Strategies"
      ],
      "metadata": {
        "id": "0UBxZ47INdbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_tensorrt\n",
        "!pip install tensorrt\n",
        "!pip install pycuda"
      ],
      "metadata": {
        "id": "wB5QGf9mtO4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA-AI-IOT/torch2trt\n",
        "!python ./torch2trt/setup.py install --plugins"
      ],
      "metadata": {
        "id": "yE3-MNRSgD6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "JKMuG_yWpPXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_tensorrt\n",
        "\n",
        "model = BertClassifier().eval()\n",
        "\n",
        "inputs = list([torch_tensorrt.Input(\n",
        "          min_shape=[64,],\n",
        "          opt_shape=[128,],\n",
        "          max_shape=[512,],\n",
        "          dtype=torch.int64,\n",
        "        )])\n",
        "\n",
        "enabled_precisions = set({torch.uint8, torch.int16, torch.int32, torch.int64})\n",
        "\n",
        "trt_ts_module = torch_tensorrt.compile(model=model, inputs=inputs, enabled_precisions=enabled_precisions)\n",
        "\n",
        "inputs = tokenizer.encode_plus(text=samples.tolist())\n",
        "ids = torch.from_numpy(np.asarray(a=inputs['input_ids']))\n",
        "ids_halved = ids.to('cuda').half()\n",
        "torch.jit.save(trt_ts_module, \"trt_ts_module.ts\")\n",
        "\n",
        "cprint(text=f'ids:\\n{ids}', color='white')\n",
        "cprint(text=f'ids_halved:\\n{ids_halved}', color='magenta')"
      ],
      "metadata": {
        "id": "lz4ZtAdNfkjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OWuUJXdxfk5D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}