{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TwintUtils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Twint object for a web-scrape query\n",
    "c = twint.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noData'globalObjects'\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:'globalObjects'\n",
      "'globalObjects' [x] run.Feed[!] if you get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!"
     ]
    }
   ],
   "source": [
    "tweets = get_tweets(**{\"Username\": \"FoxNews\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIONS = [\"Username\", # scrapes tweets from the specified user\n",
    "           \"User_id\", # scrapes tweets from the user with the specified ID\n",
    "           \"Search\", # scrapes tweets associated with the specified search terms\n",
    "           \"Geo\", # format lat,lon,radius with lat, lon in decimal degrees and radius ending with\n",
    "           \"Near\", # toponym, scrapes tweets near the specified location\n",
    "           \"Year\", # scrapes tweets before the specified year\n",
    "           \"Since\", # format YYYY-MM-DD, scrapes tweets after the specified date\n",
    "           \"Until\", # format YYYY-MM-DD, scrapes tweets before the specified date\n",
    "           \"Verified\", # scrapes tweets by verified users\n",
    "           \"Limit\", # NOTE: even when you specify the limit below 20 it will still return 20\n",
    "           \"To\", # scrapes tweets sent to the specified user\n",
    "           \"All\", # scrapes tweets sent to or from or mentioning the specified user\n",
    "           \"Images\", # scrapes tweets with images\n",
    "           \"Videos\", # scrapes tweets with videos\n",
    "           \"Media\", # scrapes tweets with images or videos\n",
    "           \"Popular_tweets\", # scrapes popular tweets if True, most recent if False\n",
    "           \"Native_retweets\", # scrapes native retweets\n",
    "           \"Min_likes\", # scrapes tweets with at least the specified number of likes\n",
    "           \"Min_retweets\", # scrapes tweets with at least the specified number of retweets\n",
    "           \"Min_replies\", # scrapes tweets with at least the specified number of replies\n",
    "           \"Links\", # includes tweets with links if \"include\", excludes if \"exclude\"\n",
    "           \"Source\", # scrapes tweets sent with the specified source client\n",
    "           \"Members_list\", # list ID, scrapes tweets by users in the specified list\n",
    "           \"Filter_retweets\"] # scrapes non-retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(**kwargs):\n",
    "    \"\"\"Get tweets that match given search\"\"\"\n",
    "    # Create Twint object for a web-scrape query\n",
    "    config = twint.Config()\n",
    "    # Store_object stores tweets in list\n",
    "    config.Store_object = True\n",
    "    config.Hide_output = True\n",
    "    # Remove non-English tweets\n",
    "    config.Lang = \"en\"\n",
    "    # Tweets are scraped in batches of 20\n",
    "    config.Limit = 20\n",
    "    # If Twitter says there is no data, Twint retries to scrape Retries_count times\n",
    "    config.Retries_count = 0\n",
    "    for option in OPTIONS:\n",
    "        if option in kwargs:\n",
    "            vars(config)[option] = kwargs[option]\n",
    "    #print(config)\n",
    "    config.Pandas = True\n",
    "    twint.output.tweets_list = []\n",
    "    # Run the search on the Twint object\n",
    "    twint.run.Search(config)\n",
    "    # List comprehension hard-limits number of tweets\n",
    "    Tweets_df = twint.storage.panda.Tweets_df\n",
    "    #return [tweet.__dict__ afor i,tweet in enumerate(twint.output.tweets_list) if i < config.Limit]\n",
    "    return Tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts = {'Search':'biden', 'Username':'FoxNews'}\n",
    "twts = get_tweets(**opts)\n",
    "\n",
    "len(twts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cce259c0d54fe5bffe13af26804447aa3dbdd9a7daf1d33523d66f0df070ca6e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('Twitter': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
